{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6dbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "from your_db_module import create_mental_health_db\n",
    "from shared.state import MainState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory_node(state: MainState) -> MainState:\n",
    "    try:\n",
    "        user_id = state.get(\"user_id\")\n",
    "        \n",
    "        if not user_id:\n",
    "            print(\"no user_id provided\")\n",
    "            return {\n",
    "                \"past_conversation\": [],\n",
    "                \"user_scores\": None,\n",
    "                \"user_decay_scores\": None,\n",
    "                \"last_update_timestamp\": None,\n",
    "                \"calc_result\": None\n",
    "            }\n",
    "        \n",
    "        # Convert to ObjectId if string\n",
    "        if isinstance(user_id, str):\n",
    "            user_id = ObjectId(user_id)\n",
    "        \n",
    "        with create_mental_health_db(\"mongodb://host.docker.internal:27017/\") as db:\n",
    "            user = db.get_user(user_id)\n",
    "            \n",
    "            if user:\n",
    "                # Load existing user data\n",
    "                past_conversation = db.get_conversation_history(user_id) or []\n",
    "                user_scores = db.get_user_scores(user_id)\n",
    "                user_decay_scores = db.get_decay_scores(user_id)\n",
    "                \n",
    "                print(f\"loaded data for user: {user_id}\")\n",
    "                \n",
    "                return {\n",
    "                    \"past_conversation\": past_conversation,\n",
    "                    \"user_scores\": user_scores,\n",
    "                    \"user_decay_scores\": user_decay_scores,\n",
    "                    \"last_update_timestamp\": user.get(\"last_update_timestamp\"),\n",
    "                    \"calc_result\": user.get(\"calc_result\")\n",
    "                }\n",
    "            else:\n",
    "                # New user\n",
    "                print(f\"new user: {user_id}\")\n",
    "                return {\n",
    "                    \"past_conversation\": [],\n",
    "                    \"user_scores\": None,\n",
    "                    \"user_decay_scores\": None,\n",
    "                    \"last_update_timestamp\": None,\n",
    "                    \"calc_result\": None\n",
    "                }\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"load failed: {e}\")\n",
    "        return {\n",
    "            \"past_conversation\": [],\n",
    "            \"user_scores\": None,\n",
    "            \"user_decay_scores\": None,\n",
    "            \"last_update_timestamp\": None,\n",
    "            \"calc_result\": None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_path_AandB_node(state: MainState) -> MainState:\n",
    "    # Check what data we have from both paths\n",
    "    path_a_results = state.get(\"semantic_search_a_results\", [])\n",
    "    path_b_results = state.get(\"semantic_search_b_results\", [])\n",
    "    warning_text = state.get(\"warning_text\", \"\")\n",
    "    calc_result = state.get(\"calc_result\", 0.0)\n",
    "    \n",
    "    # Simple status reporting\n",
    "    if path_a_results and path_b_results:\n",
    "        print(\"merged paths A and B\")\n",
    "    elif path_a_results:\n",
    "        print(\"merged path A only\")\n",
    "    elif path_b_results:\n",
    "        print(\"merged path B only\")\n",
    "    else:\n",
    "        print(\"merged empty paths\")\n",
    "    \n",
    "    # Simple passthrough - no new fields needed\n",
    "    # All data already exists in state from both subgraphs\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_generator_node(state: MainState) -> MainState:\n",
    "    try:\n",
    "        user_query = state.get(\"user_query\", \"\")\n",
    "        path_a_results = state.get(\"semantic_search_a_results\", [])\n",
    "        path_b_results = state.get(\"semantic_search_b_results\", [])\n",
    "        warning_text = state.get(\"warning_text\", \"\")\n",
    "        evaluation_feedback = state.get(\"evaluation_feedback\", \"\")\n",
    "        \n",
    "        # Build context from both paths\n",
    "        context_sources = []\n",
    "        \n",
    "        # Add PATH A results (graded documents)\n",
    "        for doc in path_a_results:\n",
    "            context_sources.append(doc.get(\"text\", \"\"))\n",
    "        \n",
    "        # Add PATH B results (search results) \n",
    "        for doc in path_b_results:\n",
    "            context_sources.append(doc.get(\"text\", \"\"))\n",
    "        \n",
    "        # Handle no context case\n",
    "        if not context_sources:\n",
    "            print(\"no context available\")\n",
    "            return {\n",
    "                \"answer\": \"I understand you're reaching out for support. While I'm experiencing some technical difficulties right now, I want you to know that your concerns are valid. If you're in immediate distress, please contact a mental health professional or crisis helpline. Otherwise, please try again in a few moments.\"\n",
    "            }\n",
    "        \n",
    "        # Build context text\n",
    "        context_text = \"\\n\".join([f\"- {source[:200]}...\" for source in context_sources])\n",
    "        \n",
    "        # Add feedback if available\n",
    "        feedback_section = \"\"\n",
    "        if evaluation_feedback:\n",
    "            feedback_section = f\"\\n\\nImprove based on feedback: {evaluation_feedback}\"\n",
    "        \n",
    "        # Simplified prompt\n",
    "        prompt = (\n",
    "            f\"You are a mental health support AI. Provide compassionate, evidence-based guidance.\\n\\n\"\n",
    "            f\"User query: {user_query}\\n\\n\"\n",
    "            f\"Context information:\\n{context_text}\\n\\n\"\n",
    "            f\"Assessment: {warning_text if warning_text else 'No specific concerns detected'}{feedback_section}\\n\\n\"\n",
    "            f\"Provide a supportive response (max 300 words) that:\\n\"\n",
    "            f\"- Addresses the user's query directly\\n\"\n",
    "            f\"- Uses warm, empathetic language\\n\"\n",
    "            f\"- Includes practical coping strategies if relevant\\n\"\n",
    "            f\"- Acknowledges any mental health concerns sensitively\\n\"\n",
    "            f\"- Reminds user this is supportive information, not professional therapy\"\n",
    "        )\n",
    "        \n",
    "        llm_response = llm_model.invoke(prompt)\n",
    "        answer = llm_response.content.strip()  # Fixed LLM response parsing\n",
    "        \n",
    "        print(f\"answer generated: {len(answer)} chars\")\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"answer generation failed: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"I understand you're reaching out for support. While I'm experiencing some technical difficulties right now, I want you to know that your concerns are valid. If you're in immediate distress, please contact a mental health professional or crisis helpline. Otherwise, please try again in a few moments.\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5eb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRIES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_node(state: MainState) -> MainState:\n",
    "    try:\n",
    "        user_query = state.get(\"user_query\", \"\")\n",
    "        answer = state.get(\"answer\", \"\")\n",
    "        \n",
    "        # Simple retry tracking (since MainState doesn't have retry counter)\n",
    "        evaluation_feedback = state.get(\"evaluation_feedback\", \"\")\n",
    "        current_attempt = 1 if not evaluation_feedback else 2\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Evaluate this mental health AI response (score 0-100):\\n\\n\"\n",
    "            f\"User query: {user_query}\\n\"\n",
    "            f\"AI response: {answer}\\n\\n\"\n",
    "            f\"Score based on: empathy, safety, relevance, professionalism\\n\"\n",
    "            f\"Deduct for: medical advice, inappropriate tone, harmful content\\n\"\n",
    "            f\"If score below 75, provide brief improvement feedback.\"\n",
    "        )\n",
    "        \n",
    "        llm_response = llm_model.with_structured_output(EvaluationResponse).invoke(prompt)\n",
    "        \n",
    "        score = llm_response.score\n",
    "        feedback = llm_response.feedback if score < 75 else \"\"\n",
    "        \n",
    "        # Decision logic\n",
    "        if score >= 75:\n",
    "            print(f\"evaluation passed: {score}\")\n",
    "            return {\n",
    "                \"evaluation_result\": \"ok\",\n",
    "                \"evaluation_feedback\": \"\"\n",
    "            }\n",
    "        elif current_attempt >= MAX_RETRIES:\n",
    "            print(f\"evaluation failed but max retries reached: {score}\")\n",
    "            return {\n",
    "                \"evaluation_result\": \"ok\",  # Accept to avoid infinite loop\n",
    "                \"evaluation_feedback\": \"\"\n",
    "            }\n",
    "        else:\n",
    "            print(f\"evaluation failed, retry: {score}\")\n",
    "            return {\n",
    "                \"evaluation_result\": \"Not ok\",\n",
    "                \"evaluation_feedback\": feedback\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"evaluation failed: {e}\")\n",
    "        return {\n",
    "            \"evaluation_result\": \"ok\",  # Fail-safe to continue\n",
    "            \"evaluation_feedback\": \"\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed\n",
    "from bson import ObjectId\n",
    "from your_db_module import create_mental_health_db\n",
    "\n",
    "def save_memory_node(state: MainState) -> MainState:\n",
    "    try:\n",
    "        user_id = state.get(\"user_id\")\n",
    "        user_query = state.get(\"user_query\", \"\")\n",
    "        answer = state.get(\"answer\", \"\")\n",
    "        \n",
    "        if not user_id:\n",
    "            print(\"no user_id to save\")\n",
    "            return {}\n",
    "        \n",
    "        # Convert to ObjectId if string\n",
    "        if isinstance(user_id, str):\n",
    "            user_id = ObjectId(user_id)\n",
    "        \n",
    "        with create_mental_health_db(\"mongodb://host.docker.internal:27017/\") as db:\n",
    "            # Save conversation (APPEND pattern)\n",
    "            conversation_saved = db.append_conversation(user_id, user_query, answer)\n",
    "            \n",
    "            # Prepare data for bulk update (OVERWRITE pattern)  \n",
    "            update_data = {}\n",
    "            if state.get(\"user_scores\") is not None:\n",
    "                update_data[\"user_scores\"] = state.get(\"user_scores\")\n",
    "            if state.get(\"user_decay_scores\") is not None:\n",
    "                update_data[\"user_decay_scores\"] = state.get(\"user_decay_scores\") \n",
    "            if state.get(\"last_update_timestamp\") is not None:\n",
    "                update_data[\"last_update_timestamp\"] = state.get(\"last_update_timestamp\")\n",
    "            if state.get(\"calc_result\") is not None:\n",
    "                update_data[\"calc_result\"] = state.get(\"calc_result\")\n",
    "            \n",
    "            # Save metrics data\n",
    "            metrics_saved = db.bulk_update_user(user_id, update_data) if update_data else True\n",
    "            \n",
    "            if conversation_saved and metrics_saved:\n",
    "                print(f\"memory saved for user: {user_id}\")\n",
    "            else:\n",
    "                print(f\"partial save for user: {user_id}\")\n",
    "            \n",
    "            return {}  # Simple completion - no new state fields needed\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"memory save failed: {e}\")\n",
    "        return {}  # Continue graph execution even on save failure"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
